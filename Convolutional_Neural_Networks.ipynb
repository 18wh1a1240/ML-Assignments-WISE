{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# -*- coding: utf-8 -*-",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Convolutional_Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/18wh1a1240/ML-Assignments-WISE/blob/main/Convolutional_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9W2q8KdGnEE"
      },
      "source": [
        "##### Objective:\n",
        "##### 1) To classify images of cats and dogs\n",
        "##### 2) Build Convolutional Neural Networks\n",
        "##### 3) Performance of the model\n",
        "\n",
        "\n",
        "# Library Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFY0dZBLGnEG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e105d57-d52d-4726-8dfc-b1db9951d0af"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUPoqsHzAkjG"
      },
      "source": [
        "# Unzipping and Loading Dataset to the Console"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnOTmIs0HhnY"
      },
      "source": [
        "!unzip \"<File Path of the cats_and_dogs_filtered.zip in mounted drive>\" -d \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI413faCGnEM"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBgZCZknGnEM"
      },
      "source": [
        "base_dir = os.path.join(os.getcwd(), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0jxA-AnGnEP"
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMe-ViH8GnET"
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJzzmevUGnEW"
      },
      "source": [
        "# Setting Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSlEdblMGnEX"
      },
      "source": [
        "BATCH_SIZE = 100  # Number of training examples to process before updating our models variables\n",
        "IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS8qOpHqGnEa"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_jAYdUeGnEb"
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfsbssCVGnEd",
        "outputId": "2f6de033-e118-4d92-807e-4c53db2b5702"
      },
      "source": [
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (150, 150, 3), activation = 'relu'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euLSLtEBGnEh"
      },
      "source": [
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(2, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BfFCo8AGnEm"
      },
      "source": [
        "# Step 1 & 2 with more hidden layers\n",
        "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(2,2))\n",
        "\n",
        "classifier.add(Conv2D(128, (3,3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(2,2))\n",
        "\n",
        "classifier.add(Conv2D(128, (3,3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(2,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKGZF_wkGnEp",
        "outputId": "1c5a9868-c5ed-421d-808c-ea47d6e06693"
      },
      "source": [
        "# Step 3 - Dropout\n",
        "classifier.add(Dropout(0.5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miKHcyhsGnEr"
      },
      "source": [
        "Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHwP1bAdGnEr"
      },
      "source": [
        "# Step 4 - Flattening\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Atogo6OGnEt"
      },
      "source": [
        "# Step 5 - Full connection\n",
        "classifier.add(Dense(units = 512, activation = 'relu'))\n",
        "classifier.add(Dense(units = 2, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2D8uzkTGnEw"
      },
      "source": [
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyj8eATBGnE0",
        "outputId": "32b310f9-3a7f-4467-93ce-fcf81aac1b69"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 3,453,634\n",
            "Trainable params: 3,453,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7coWzjDGnE2"
      },
      "source": [
        "# Data Augmentation and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feL5q-EGGnE3"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_bkfD5jGnE6",
        "outputId": "4922fc45-2545-47c6-b362-f6ac6adbfd8c"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                 directory=train_dir,\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN39ejY5GnE8"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xSn1-zjGnE-",
        "outputId": "b28991f0-d2c9-4711-c085-b00fb0d3a670"
      },
      "source": [
        "validation_set = validation_datagen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                        directory=validation_dir,\n",
        "                                                        target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQaWKTrPGnFA"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEUs370fGnFG"
      },
      "source": [
        "epochs=100\n",
        "history = classifier.fit_generator(\n",
        "    training_set,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_set,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1L-81KmGnFK"
      },
      "source": [
        "# Training Result Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W6NYtVmGnFL"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}